Because ip default namespace are in pending status why because the ports by default search for the ec2 I mean node group so the annotation in the deployment , the default deployment was like that only so we need to remove those annotations form the default deployment which we can achieve from the patching , so I used above command but not working ?

aws eks update-kubeconfig --name FargateCluster

kubectl get nodes

kubectl patch deployment coredns -n kube-system --type=json -p='[
  {"op": "remove", "path": "/spec/template/spec/affinity"},
  {"op": "remove", "path": "/spec/template/spec/topologySpreadConstraints"}
]'

wget https://s3.us-west-2.amazonaws.com/amazon-eks/docs/eks-console-full-access.yaml

kubectl apply -f eks-console-full-access.yaml

kubectl get node

aws eks list-fargate-profiles --cluster-name Fargate-cluster

ubuntu@k8smaster:~/sam$ kubectl create secret docker-registry regcred \
  --docker-server=https://602401143452.dkr.ecr.ap-south-1.amazonaws.com \
  --docker-username=AWS \
  --docker-password=$(aws ecr get-login-password --region ap-south-1)

-----------------------------------------------------------------------------------------------------------------------------------------------------

Fall Back to default k8s
========================

ubuntu@k8smaster:~/sam$ kubectl config get-contexts
CURRENT   NAME                                                         CLUSTER                                                      AUTHINFO                                                     NAMESPACE
*         arn:aws:eks:ap-south-1:641104658931:cluster/FargateCluster   arn:aws:eks:ap-south-1:641104658931:cluster/FargateCluster   arn:aws:eks:ap-south-1:641104658931:cluster/FargateCluster
          kubernetes-admin@kubernetes                                  kubernetes                                                   kubernetes-admin


kubectl config use-context kubernetes-admin@kubernetes

kubectl get node

------------------------------------------------------------------------------------------------------------------------------------------------------------

  Warning  FailedScheduling  4m27s  default-scheduler  0/1 nodes are available: 1 node(s) had untolerated taint {eks.amazonaws.com/compute-type: fargate}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.
ubuntu@k8smaster:~/sam$


kubectl rollout restart -n kube-system deployment coredns



{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowEKSClusterAccess",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::<your-account-id>:role/<your-eks-role>"
            },
            "Action": "ecr:BatchGetImage"
        }
    ]
}









kubectl patch deployment coredns \
-n kube-system
-type json \
37m
-p='[{"op": "remove", "path": "/spec/template/metadata/annotations/eks.amazonaws.com/compute-type"}]'





